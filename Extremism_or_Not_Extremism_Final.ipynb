{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extremism or Not-Extremism Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCQPZKceUvWi"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hboSU-dmUwbV",
        "outputId": "443fa296-06b1-47e2-e989-778b32d7b27c"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9VfHSuxUy8l"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2QEkA3TU_Fq"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/DATASET/my_dataset.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRxEnWb3VD57",
        "outputId": "68e080d0-6ed6-4928-d79d-57628958f348"
      },
      "source": [
        "print(dataset.head())\r\n",
        "print(dataset.info())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Label                                               Text\n",
            "0  Extremism  শিক্ষার্থীদের আন্দোলনকে ভিন্নখাতে নিতে নৈরাজ্য...\n",
            "1  Extremism  মাননীয় প্রধান মন্ত্রী,,কোন আইন আপনার সুশাসনে প...\n",
            "2  Extremism  নৈরাজ্য সৃষ্টি করে দূর্নীতিবাজ তারেক রহমানকে র...\n",
            "3  Extremism  বাংলাদেশ নামটা পরিবতন করে আওয়ামি লীগ দেশ করা দ...\n",
            "4  Extremism                      সময় টিভি আওয়ামী লীগের দালাল\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8545 entries, 0 to 8544\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Label   8545 non-null   object\n",
            " 1   Text    8541 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 133.6+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3Gv6OUrVLB7"
      },
      "source": [
        "X = dataset.drop([\"Label\"],axis=1)\r\n",
        "y = dataset[\"Label\"]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVvNnOZrVOKj",
        "outputId": "b4c079ca-1a30-4ef5-d3b9-4d8c9993328f"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "# convert class labels to binary values, 0 = ham and 1 = spam\r\n",
        "encoder = LabelEncoder()\r\n",
        "Y = encoder.fit_transform(y)\r\n",
        "\r\n",
        "print(Y[:10])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1qXLtiwVTHt",
        "outputId": "4b8c8620-89e2-4da9-acfd-58ec74ff210e"
      },
      "source": [
        "pip install bnlp_toolkit"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bnlp_toolkit in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.19.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (3.6.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (0.1.95)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (0.3.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (3.2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from bnlp_toolkit) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->bnlp_toolkit) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim->bnlp_toolkit) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (4.41.1)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from sklearn-crfsuite->bnlp_toolkit) (0.9.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0dNc2qfVVlg",
        "outputId": "c64e1eca-45c9-4dc5-93f3-c0edf8d10674"
      },
      "source": [
        "pip install BnPreprocessing"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: BnPreprocessing in /usr/local/lib/python3.7/dist-packages (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVU_-CdAVYKx"
      },
      "source": [
        "import BnPreprocessing as pp\r\n",
        "dataset['Text'] = dataset['Text'].apply(lambda x: pp.remove_noise(str(x)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPKfk054VahL"
      },
      "source": [
        "from bnlp import NLTKTokenizer\r\n",
        "\r\n",
        "all_words = []\r\n",
        "bnltk = NLTKTokenizer()\r\n",
        "\r\n",
        "\r\n",
        "for message in dataset['Text']:\r\n",
        "    word_tokens = bnltk.word_tokenize(message)\r\n",
        "    for w in word_tokens:\r\n",
        "        all_words.append(w)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMkkw0SEVeWR"
      },
      "source": [
        "def find_features(message):\r\n",
        "    words = bnltk.word_tokenize(message)\r\n",
        "    features = {}\r\n",
        "    for word in all_words:\r\n",
        "        features[word] = (word in words)\r\n",
        "\r\n",
        "    return features"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qFhK-FTVmHb"
      },
      "source": [
        "# Now lets do it for all the messages\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "messages = zip(dataset['Text'], Y)\r\n",
        "\r\n",
        "# define a seed for reproducibility\r\n",
        "seed = 1\r\n",
        "np.random.seed = seed\r\n",
        "\r\n",
        "# call find_features function for each SMS message\r\n",
        "featuresets = [(find_features(text), label) for (text, label) in messages]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGREcyurVoHH"
      },
      "source": [
        "# we can split the featuresets into training and testing datasets using sklearn\r\n",
        "from sklearn import model_selection\r\n",
        "\r\n",
        "# split the data into training and testing datasets\r\n",
        "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEhznPD9hilF",
        "outputId": "85ad42f0-2c99-4b6c-c94e-19a9d89abd98"
      },
      "source": [
        "print(len(training))\r\n",
        "print(len(testing))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6408\n",
            "2137\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NpjfC0lY_rm"
      },
      "source": [
        "import nltk\r\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47FJeYaIWV_q",
        "outputId": "bbdbc03c-7b99-4dfe-c58b-960b5962d435"
      },
      "source": [
        "# We can use sklearn algorithms in NLTK\r\n",
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "\r\n",
        "model = SklearnClassifier(SVC(kernel = 'linear'))\r\n",
        "\r\n",
        "# train the model on the training data\r\n",
        "model.train(training)\r\n",
        "\r\n",
        "# and test on the testing dataset!\r\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\r\n",
        "print(\"SVC Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVC Accuracy: 97.84744969583528\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2hptfM-WYxP"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\r\n",
        "\r\n",
        "# Define models to train\r\n",
        "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\r\n",
        "         \"Naive Bayes\"]\r\n",
        "\r\n",
        "classifiers = [\r\n",
        "    KNeighborsClassifier(),\r\n",
        "    DecisionTreeClassifier(),\r\n",
        "    RandomForestClassifier(),\r\n",
        "    LogisticRegression(),\r\n",
        "    SGDClassifier(max_iter = 100),\r\n",
        "    MultinomialNB(),\r\n",
        "    SVC(kernel = 'linear')\r\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK21QTFZcq5S",
        "outputId": "fd7af848-877c-4b5f-cec6-e40647fb11b2"
      },
      "source": [
        "model = SklearnClassifier(KNeighborsClassifier())\r\n",
        "\r\n",
        "# train the model on the training data\r\n",
        "model.train(training)\r\n",
        "\r\n",
        "# and test on the testing dataset!\r\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\r\n",
        "print(\"KNeighborsClassifier() Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier() Accuracy: 63.87459054749649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAkafkmIgzJi",
        "outputId": "3b76482c-2dd7-438e-fb55-9b4431385be1"
      },
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "model = SklearnClassifier(DecisionTreeClassifier())\r\n",
        "\r\n",
        "# train the model on the training data\r\n",
        "model.train(training)\r\n",
        "\r\n",
        "# and test on the testing dataset!\r\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\r\n",
        "print(\"DecisionTreeClassifier Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier Accuracy: 91.01544220870379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyFjhR7eg63g",
        "outputId": "c7417a5d-dab3-488a-b8da-dfa6bcc83897"
      },
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "model = SklearnClassifier(RandomForestClassifier())\r\n",
        "\r\n",
        "# train the model on the training data\r\n",
        "model.train(training)\r\n",
        "\r\n",
        "# and test on the testing dataset!\r\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\r\n",
        "print(\"Random Forest Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 92.98081422554984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVGY0jCinYvN",
        "outputId": "c200385e-c582-4a46-f297-b6817097e73b"
      },
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "model = SklearnClassifier(LogisticRegression())\r\n",
        "\r\n",
        "# train the model on the training data\r\n",
        "model.train(training)\r\n",
        "\r\n",
        "# and test on the testing dataset!\r\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\r\n",
        "print(\"LogisticRegression Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression Accuracy: 97.05194197473092\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zfrfkcUpM7_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E94XxT8qOH8",
        "outputId": "8bf13a07-e73d-4095-c4ba-3b478ad2b9e5"
      },
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "model = SklearnClassifier( SGDClassifier(max_iter = 100))\r\n",
        "\r\n",
        "# train the model on the training data\r\n",
        "model.train(training)\r\n",
        "\r\n",
        "# and test on the testing dataset!\r\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\r\n",
        "print(\" SGDClassifier(max_iter = 100) Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " SGDClassifier(max_iter = 100) Accuracy: 97.56668226485728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AH6IBSeRqbAH",
        "outputId": "d01bf770-821e-482e-f570-6d6726a6093d"
      },
      "source": [
        "from nltk.classify.scikitlearn import SklearnClassifier\r\n",
        "model = SklearnClassifier(MultinomialNB())\r\n",
        "\r\n",
        "# train the model on the training data\r\n",
        "model.train(training)\r\n",
        "\r\n",
        "# and test on the testing dataset!\r\n",
        "accuracy = nltk.classify.accuracy(model, testing)*100\r\n",
        "print(\"MultinomialNB Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB Accuracy: 98.50257370145063\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUumYZm8rIZ9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}